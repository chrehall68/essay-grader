{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Essay Grader"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The goal of this is to have the AI output whether the essay is good or bad on a scale from 0% to 100%."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# AI utilities\n",
            "import tensorflow as tf\n",
            "import keras\n",
            "import keras.layers as layers\n",
            "\n",
            "# processing utilities\n",
            "import numpy as np\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "# misc utilities\n",
            "import os\n",
            "import pickle\n",
            "import random\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "ESSAY_MAX_WORD_COUNT = 1250\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Load Glove"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "PATH_TO_GLOVE_FILE = \"./glove.6B.100d.txt\"\n",
            "GLOVE_OUTPUT_DIM = 100\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "loading preprocessed glove\n",
                  "Found 400000 word vectors.\n"
               ]
            }
         ],
         "source": [
            "embeddings = {}\n",
            "\n",
            "if not os.path.exists(\"./processed_glove.b\"):\n",
            "    print(\"loading glove from scratch\")\n",
            "    with open(PATH_TO_GLOVE_FILE) as f:\n",
            "        for line in f:\n",
            "            word, coefs = line.split(maxsplit=1)\n",
            "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
            "            embeddings[word] = coefs\n",
            "\n",
            "    print(\"Found %s word vectors.\" % len(embeddings))\n",
            "\n",
            "    with open(\"./processed_glove.b\", \"wb\") as file:\n",
            "        pickle.dump(embeddings, file)\n",
            "        file.close()\n",
            "else:\n",
            "    print(\"loading preprocessed glove\")\n",
            "    with open(\"./processed_glove.b\", \"rb\") as file:\n",
            "        embeddings = pickle.load(file)\n",
            "        file.close()\n",
            "\n",
            "    print(\"Found %s word vectors.\" % len(embeddings))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Get the Text Vectorizer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2022-10-13 14:39:34.465105: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
                  "2022-10-13 14:39:34.465244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (esuhsd-Latitude-3410): /proc/driver/nvidia/version does not exist\n",
                  "2022-10-13 14:39:34.467531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
                  "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
               ]
            }
         ],
         "source": [
            "vectorizer = layers.TextVectorization(\n",
            "    len(embeddings), standardize=\"lower\", output_sequence_length=ESSAY_MAX_WORD_COUNT\n",
            ")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# quickly learn the words (should take about 40 seconds)\n",
            "vectorizer_batch_size = 10\n",
            "quick_dataset = tf.data.Dataset.from_tensor_slices(\n",
            "    np.array(list(embeddings.keys()))\n",
            ").batch(vectorizer_batch_size)\n",
            "vectorizer.adapt(quick_dataset, steps=len(embeddings) / vectorizer_batch_size)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<tf.Tensor: shape=(1, 1250), dtype=int64, numpy=array([[214545,  80444,      1, ...,      0,      0,      0]])>"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# try it out\n",
            "vectorizer([\"I saw it, and it was cool.\"])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "# make it non-trainable\n",
            "vectorizer.trainable = False\n",
            "\n",
            "# get vocabulary\n",
            "voc = vectorizer.get_vocabulary()\n",
            "word_index = dict(zip(voc, range(len(voc))))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Make Embedding Layer"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Converted 399998 words (2 misses)\n"
               ]
            }
         ],
         "source": [
            "num_tokens = len(voc) + 2\n",
            "hits = 0\n",
            "misses = 0\n",
            "\n",
            "# Prepare embedding matrix\n",
            "embedding_matrix = np.zeros((num_tokens, GLOVE_OUTPUT_DIM))\n",
            "for word, i in word_index.items():\n",
            "    embedding_vector = embeddings.get(word)\n",
            "    if embedding_vector is not None:\n",
            "        # Words not found in embedding index will be all-zeros.\n",
            "        # This includes the representation for \"padding\" and \"OOV\"\n",
            "        embedding_matrix[i] = embedding_vector\n",
            "        hits += 1\n",
            "    else:\n",
            "        misses += 1\n",
            "print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "glove = keras.layers.Embedding(\n",
            "    num_tokens,\n",
            "    GLOVE_OUTPUT_DIM,\n",
            "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
            "    trainable=False,\n",
            ")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Compare Glove Embeddings Layer and Raw Glove"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<tf.Tensor: shape=(1, 1250, 100), dtype=float32, numpy=\n",
                     "array([[[-0.038194, -0.24487 ,  0.72812 , ..., -0.1459  ,  0.8278  ,\n",
                     "          0.27062 ],\n",
                     "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
                     "          0.      ],\n",
                     "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
                     "          0.      ],\n",
                     "        ...,\n",
                     "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
                     "          0.      ],\n",
                     "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
                     "          0.      ],\n",
                     "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
                     "          0.      ]]], dtype=float32)>"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "glove(vectorizer([\"the\"]))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
                     "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
                     "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
                     "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
                     "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
                     "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
                     "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
                     "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
                     "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
                     "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
                     "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
                     "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
                     "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
                     "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
                     "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
                     "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
                     "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "embeddings[\"the\"]\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Make Model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "def make_text_preprocessor():\n",
            "    preprocessor = keras.models.Sequential()\n",
            "    preprocessor.add(vectorizer)\n",
            "    preprocessor.add(glove)\n",
            "    return preprocessor\n",
            "\n",
            "\n",
            "def make_model(preprocessor):\n",
            "    model = keras.models.Sequential()\n",
            "    model.add(layers.Input(preprocessor.output_shape[1:]))\n",
            "\n",
            "    # slowly change from 100 to 25 numbers per word\n",
            "    model.add(layers.Conv1D(75, 5, activation=\"relu\"))\n",
            "    model.add(layers.MaxPooling1D())\n",
            "    model.add(layers.Conv1D(50, 5, activation=\"relu\"))\n",
            "    model.add(layers.MaxPooling1D())\n",
            "    model.add(layers.Conv1D(25, 5, activation=\"relu\"))\n",
            "    model.add(layers.MaxPooling1D())\n",
            "\n",
            "    # use lstm to get the meanings from sequences of words\n",
            "    model.add(layers.LSTM(512))\n",
            "\n",
            "    # get down to 1 output\n",
            "    model.add(layers.Dense(256, activation=\"relu\"))\n",
            "    model.add(layers.Dropout(0.5))\n",
            "    model.add(layers.Dense(128, activation=\"relu\"))\n",
            "    model.add(layers.Dropout(0.5))\n",
            "    model.add(layers.Dense(64, activation=\"relu\"))\n",
            "    model.add(layers.Dropout(0.3))\n",
            "\n",
            "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
            "\n",
            "    return model\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Model: \"sequential\"\n",
                  "_________________________________________________________________\n",
                  " Layer (type)                Output Shape              Param #   \n",
                  "=================================================================\n",
                  " text_vectorization (TextVec  (None, 1250)             0         \n",
                  " torization)                                                     \n",
                  "                                                                 \n",
                  " embedding (Embedding)       (None, 1250, 100)         40000200  \n",
                  "                                                                 \n",
                  "=================================================================\n",
                  "Total params: 40,000,200\n",
                  "Trainable params: 0\n",
                  "Non-trainable params: 40,000,200\n",
                  "_________________________________________________________________\n"
               ]
            }
         ],
         "source": [
            "text_preprocessor = make_text_preprocessor()\n",
            "text_preprocessor.summary()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Model: \"sequential_1\"\n",
                  "_________________________________________________________________\n",
                  " Layer (type)                Output Shape              Param #   \n",
                  "=================================================================\n",
                  " conv1d (Conv1D)             (None, 1246, 75)          37575     \n",
                  "                                                                 \n",
                  " max_pooling1d (MaxPooling1D  (None, 623, 75)          0         \n",
                  " )                                                               \n",
                  "                                                                 \n",
                  " conv1d_1 (Conv1D)           (None, 619, 50)           18800     \n",
                  "                                                                 \n",
                  " max_pooling1d_1 (MaxPooling  (None, 309, 50)          0         \n",
                  " 1D)                                                             \n",
                  "                                                                 \n",
                  " conv1d_2 (Conv1D)           (None, 305, 25)           6275      \n",
                  "                                                                 \n",
                  " max_pooling1d_2 (MaxPooling  (None, 152, 25)          0         \n",
                  " 1D)                                                             \n",
                  "                                                                 \n",
                  " lstm (LSTM)                 (None, 512)               1101824   \n",
                  "                                                                 \n",
                  " dense (Dense)               (None, 256)               131328    \n",
                  "                                                                 \n",
                  " dropout (Dropout)           (None, 256)               0         \n",
                  "                                                                 \n",
                  " dense_1 (Dense)             (None, 128)               32896     \n",
                  "                                                                 \n",
                  " dropout_1 (Dropout)         (None, 128)               0         \n",
                  "                                                                 \n",
                  " dense_2 (Dense)             (None, 64)                8256      \n",
                  "                                                                 \n",
                  " dropout_2 (Dropout)         (None, 64)                0         \n",
                  "                                                                 \n",
                  " dense_3 (Dense)             (None, 1)                 65        \n",
                  "                                                                 \n",
                  "=================================================================\n",
                  "Total params: 1,337,019\n",
                  "Trainable params: 1,337,019\n",
                  "Non-trainable params: 0\n",
                  "_________________________________________________________________\n"
               ]
            }
         ],
         "source": [
            "grader = make_model(text_preprocessor)\n",
            "grader.summary()\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Load Data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "# essay readers\n",
            "\n",
            "\n",
            "def read_essay(path: str) -> str:\n",
            "    with open(path, \"r\") as essay:\n",
            "        ret = essay.read()\n",
            "    return ret\n",
            "\n",
            "\n",
            "def recursive_helper(path: str) -> list:\n",
            "    ret = []\n",
            "    for file in os.listdir(path):\n",
            "        cur_path = path + \"/\" + file\n",
            "        if os.path.isdir(cur_path):\n",
            "            ret.extend(recursive_helper(cur_path))\n",
            "        else:\n",
            "            ret.append(read_essay(cur_path))\n",
            "    return ret\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_positive_samples():\n",
            "    \"\"\"\n",
            "    Returns the list of strings that have worked.\n",
            "    Searches under data/worked\n",
            "    \"\"\"\n",
            "    ret = recursive_helper(\"data/worked/\")\n",
            "    labels = [random.randint(85, 100) / 100 for i in range(len(ret))]\n",
            "\n",
            "    print(f\"Loaded {len(ret)} essays that worked\")\n",
            "\n",
            "    return ret, labels\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loaded 2 essays that worked\n"
               ]
            }
         ],
         "source": [
            "samples, labels = get_positive_samples()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [],
         "source": [
            "NUM_RANDOM_SAMPLES = 500\n",
            "RANDOM_SAMPLE_MIN_LENGTH = 10\n",
            "RANDOM_SAMPLE_MAX_LENGTH = 1000\n",
            "\n",
            "\n",
            "def get_random_samples():\n",
            "    global voc\n",
            "\n",
            "    # the list with all the essays\n",
            "    ret = []\n",
            "\n",
            "    # generate random essays\n",
            "    for i in range(NUM_RANDOM_SAMPLES):\n",
            "        essay = \"\"\n",
            "        essay_length = random.randint(\n",
            "            RANDOM_SAMPLE_MIN_LENGTH, RANDOM_SAMPLE_MAX_LENGTH\n",
            "        )\n",
            "\n",
            "        # add random words\n",
            "        for x in range(essay_length):\n",
            "            essay += random.choice(voc) + \" \"\n",
            "\n",
            "        # remove trailing whitespace\n",
            "        essay = essay.strip()\n",
            "\n",
            "        # add it to the samples\n",
            "        ret.append(essay)\n",
            "\n",
            "    labels = [0 for i in range(len(ret))]\n",
            "\n",
            "    print(f\"Loaded {len(ret)} random failures\")\n",
            "\n",
            "    return ret, labels\n",
            "\n",
            "\n",
            "def get_absolute_failures():\n",
            "    \"\"\"\n",
            "    Assumes that there are absolute failures of essays\n",
            "    underneath data/failures/\n",
            "    \"\"\"\n",
            "    ret = recursive_helper(\"data/failures\")\n",
            "    labels = [random.randint(0, 10) / 100 for i in range(len(ret))]\n",
            "\n",
            "    print(f\"Loaded {len(ret)} absolute failures.\")\n",
            "\n",
            "    return ret, labels\n",
            "\n",
            "\n",
            "def get_ok_failures():\n",
            "    \"\"\"\n",
            "    Assumes that there are ok essays (somewhere between 0.3 to 0.5)\n",
            "    under data/ok/\n",
            "    \"\"\"\n",
            "    ret = recursive_helper(\"data/ok/\")\n",
            "    labels = [random.randint(30, 50) / 100 for x in range(len(ret))]\n",
            "\n",
            "    print(f\"Loaded {len(ret)} ok failures.\")\n",
            "\n",
            "    return ret, labels\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Loaded 500 random failures\n",
                  "Loaded 1 absolute failures.\n",
                  "Loaded 1 ok failures.\n"
               ]
            }
         ],
         "source": [
            "# random samples\n",
            "_temp_samples, _temp_labels = get_random_samples()\n",
            "samples.extend(_temp_samples)\n",
            "labels.extend(_temp_labels)\n",
            "\n",
            "# failure samples\n",
            "_temp_samples, _temp_labels = get_absolute_failures()\n",
            "samples.extend(_temp_samples)\n",
            "labels.extend(_temp_labels)\n",
            "\n",
            "# ok samples\n",
            "_temp_samples, _temp_labels = get_ok_failures()\n",
            "samples.extend(_temp_samples)\n",
            "labels.extend(_temp_labels)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2022-10-13 14:40:20.707516: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 252000000 exceeds 10% of free system memory.\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "TensorShape([504, 1250, 100])"
                  ]
               },
               "execution_count": 21,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "processed_samples = text_preprocessor(tf.constant(samples))\n",
            "processed_samples.shape\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(504,)"
                  ]
               },
               "execution_count": 22,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "processed_labels = np.array(labels)\n",
            "processed_labels.shape\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Train"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [],
         "source": [
            "# use model.fit\n",
            "grader.compile(\n",
            "    optimizer=\"adam\",\n",
            "    loss=keras.losses.BinaryCrossentropy(),\n",
            ")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Epoch 1/3\n",
                  "14/14 [==============================] - 26s 2s/step - loss: 0.2369 - val_loss: 0.0868\n",
                  "Epoch 2/3\n",
                  "14/14 [==============================] - 20s 1s/step - loss: 0.1193 - val_loss: 0.0442\n",
                  "Epoch 2: early stopping\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "<keras.callbacks.History at 0x7f083f6c9bd0>"
                  ]
               },
               "execution_count": 24,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "grader.fit(\n",
            "    processed_samples,\n",
            "    processed_labels,\n",
            "    epochs=3,\n",
            "    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", verbose=1)],\n",
            "    validation_split=0.15,\n",
            ")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Watch the model grade you!"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "def grade(essay: str) -> float:\n",
            "    ret = grader(text_preprocessor(np.array([essay])))\n",
            "    return ret * 100\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.00200112]], dtype=float32)>"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "grade(samples[0])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.6 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.6"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
